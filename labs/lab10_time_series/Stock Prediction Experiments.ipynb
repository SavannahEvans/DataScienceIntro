{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock Market Prediction Experiments\n",
    "\n",
    "Jay Urbain, PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Predict whether future daily returns are going to be positive or negative.\n",
    "\n",
    "This is a binary classification.\n",
    "\n",
    "$Return_i=\\dfrac{AdjClose_{i}–AdjClose_{i−1}}{AdjClose_{i−1}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named backtest",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9ea27174d58d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdateutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbacktest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPortfolio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named backtest"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import operator\n",
    "import pandas.io.data\n",
    "#import pandas_datareader.data # need to update\n",
    "from sklearn.qda import QDA\n",
    "import re\n",
    "from dateutil import parser\n",
    "from backtest import Strategy, Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictors\n",
    "\n",
    "the following predictors have been selected:\n",
    "\n",
    "- [NASDAQ Composite (^IXIC Yahoo Finance)](http://finance.yahoo.com/q?s=^IXIC&ql=1)  \n",
    "Dow Jones Industrial Average (^DJI Quandl)   \n",
    "Frankfurt DAX (^GDAXI Yahoo Finance)  \n",
    "London FTSE-100 (^FTSE Yahoo Finance)  \n",
    "Paris CAC 40 (^FCHI Yahoo Finance)  \n",
    "Tokyo Nikkei-225 (^N225 Yahoo Finance)  \n",
    "Hong Kong Hang Seng (^HSI Yahoo Finance)  \n",
    "Australia ASX-200 (^AXJO Yahoo Finance)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to recap the logic is the following:\n",
    "\n",
    "1) Download 9 dataframes (NASDAQ, Dow Jones, Frankfurt, London , Paris, Tokyo, Hong Kong, Australia, S&P 500).  \n",
    "2) Compute S&P 500 daily returns and turn them into a binary variable (Up, Down). This is my output and it won’t be touched anymore.  \n",
    "3) Play with all the other columns of the 9 available dataframes (S&P 500 included) as explained in the following post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getStock(symbol, start, end):\n",
    "    \"\"\"\n",
    "    Downloads Stock from Yahoo Finance.\n",
    "    Computes daily Returns based on Adj Close.\n",
    "    Returns pandas dataframe.\n",
    "    \"\"\"\n",
    "    df =  pd.io.data.get_data_yahoo(symbol, start, end)\n",
    "\n",
    "    df.columns.values[-1] = 'AdjClose'\n",
    "    df.columns = df.columns + '_' + symbol\n",
    "    df['Return_%s' %symbol] = df['AdjClose_%s' %symbol].pct_change()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getStockFromQuandl(symbol, name, start, end):\n",
    "    \"\"\"\n",
    "    Downloads Stock from Quandl.\n",
    "    Computes daily Returns based on Adj Close.\n",
    "    Returns pandas dataframe.\n",
    "    \"\"\"\n",
    "    import Quandl\n",
    "    df =  Quandl.get(symbol, trim_start = start, trim_end = end, authtoken=\"your token\")\n",
    " \n",
    "    df.columns.values[-1] = 'AdjClose'\n",
    "    df.columns = df.columns + '_' + name\n",
    "    df['Return_%s' %name] = df['AdjClose_%s' %name].pct_change()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getStockDataFromWeb(fout, start_string, end_string):\n",
    "    \"\"\"\n",
    "    Collects predictors data from Yahoo Finance and Quandl.\n",
    "    Returns a list of dataframes.\n",
    "    \"\"\"\n",
    "    start = parser.parse(start_string)\n",
    "    end = parser.parse(end_string)\n",
    "    \n",
    "    nasdaq = getStock('^IXIC', start, end)\n",
    "    frankfurt = getStock('^GDAXI', start, end)\n",
    "    london = getStock('^FTSE', start, end)\n",
    "    paris = getStock('^FCHI', start, end)\n",
    "    hkong = getStock('^HSI', start, end)\n",
    "    nikkei = getStock('^N225', start, end)\n",
    "    australia = getStock('^AXJO', start, end)\n",
    "    \n",
    "    djia = getStockFromQuandl(\"YAHOO/INDEX_DJI\", 'Djia', start_string, end_string) \n",
    "    \n",
    "    out =  pd.io.data.get_data_yahoo(fout, start, end)\n",
    "    out.columns.values[-1] = 'AdjClose'\n",
    "    out.columns = out.columns + '_Out'\n",
    "    out['Return_Out'] = out['AdjClose_Out'].pct_change()\n",
    "    \n",
    "    return [out, nasdaq, djia, frankfurt, london, paris, hkong, nikkei, australia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2004-08-19     50.119968\n",
      "2004-08-20     54.100990\n",
      "2004-08-23     54.645447\n",
      "2004-08-24     52.382705\n",
      "2004-08-25     52.947145\n",
      "2004-08-26     53.901190\n",
      "2004-08-27     53.022069\n",
      "2004-08-30     50.954132\n",
      "2004-08-31     51.133953\n",
      "2004-09-01     50.075011\n",
      "2004-09-02     50.704382\n",
      "2004-09-03     49.955130\n",
      "2004-09-07     50.739348\n",
      "2004-09-08     51.098988\n",
      "2004-09-09     51.103983\n",
      "2004-09-10     52.612476\n",
      "2004-09-13     53.696398\n",
      "2004-09-14     55.689407\n",
      "2004-09-15     55.944152\n",
      "2004-09-16     56.928171\n",
      "2004-09-17     58.686414\n",
      "2004-09-20     59.620484\n",
      "2004-09-21     58.861240\n",
      "2004-09-22     59.130972\n",
      "2004-09-23     60.349754\n",
      "2004-09-24     59.855246\n",
      "2004-09-27     59.071031\n",
      "2004-09-28     63.366744\n",
      "2004-09-29     65.474638\n",
      "2004-09-30     64.735377\n",
      "                 ...    \n",
      "2004-11-29     90.434722\n",
      "2004-11-30     90.899259\n",
      "2004-12-01     89.890261\n",
      "2004-12-02     89.610541\n",
      "2004-12-03     90.110048\n",
      "2004-12-06     88.057091\n",
      "2004-12-07     85.629519\n",
      "2004-12-08     84.905237\n",
      "2004-12-09     86.628517\n",
      "2004-12-10     85.739409\n",
      "2004-12-13     85.140003\n",
      "2004-12-14     89.255894\n",
      "2004-12-15     89.800354\n",
      "2004-12-16     88.147006\n",
      "2004-12-17     89.950202\n",
      "2004-12-20     92.417739\n",
      "2004-12-21     91.783372\n",
      "2004-12-22     93.057102\n",
      "2004-12-23     93.856304\n",
      "2004-12-27     95.859305\n",
      "2004-12-28     96.283884\n",
      "2004-12-29     96.353808\n",
      "2004-12-30     98.701465\n",
      "2004-12-31     96.298863\n",
      "2005-01-03    101.253921\n",
      "2005-01-04     97.153010\n",
      "2005-01-05     96.658507\n",
      "2005-01-06     94.180978\n",
      "2005-01-07     96.828337\n",
      "2005-01-10     97.432738\n",
      "Name: Adj Close, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                 Open       High        Low      Close    Volume  Adj Close\n",
      "Date                                                                       \n",
      "2014-12-01  42.009998  42.380001  42.009998  42.080002  10802400  41.175240\n",
      "2014-12-02  41.900002  42.360001  41.860001  42.180000   9081800  41.273088\n",
      "2014-12-03  41.939999  42.139999  41.639999  42.060001  10326000  41.155669\n",
      "2014-12-04  42.119999  42.119999  41.490002  41.889999   9177100  40.989322\n",
      "2014-12-05  42.020000  42.020000  41.590000  41.930000   8925300  41.028463\n",
      "2014-12-08  41.910000  42.029999  41.330002  41.369999  12766500  40.480502\n",
      "2014-12-09  40.980000  41.930000  40.889999  41.869999  13897500  40.969752\n",
      "2014-12-10  41.700001  41.810001  40.880001  40.919998  12547600  40.040177\n",
      "2014-12-11  41.119999  41.639999  40.709999  40.759998  12395800  39.883617\n",
      "2014-12-12  40.240002  40.779999  39.919998  39.950001  14108200  39.091036\n",
      "2014-12-15  41.209999  41.650002  40.770000  41.110001  22343100  40.226094\n",
      "2014-12-16  40.889999  41.360001  40.610001  40.630001  16424500  39.756415\n",
      "2014-12-17  41.060001  41.630001  40.680000  41.160000  18151000  40.275018\n",
      "2014-12-18  43.830002  45.369999  43.570000  45.349998  54495600  44.374928\n",
      "2014-12-19  45.099998  46.150002  44.980000  46.000000  41782200  45.010954\n",
      "2014-12-22  45.570000  46.049999  45.410000  45.650002  21264400  44.668481\n",
      "2014-12-23  45.529999  46.500000  45.459999  46.009998  14042400  45.020737\n",
      "2014-12-24  46.360001  46.709999  46.150002  46.230000  10238200  45.236008\n",
      "2014-12-26  46.189999  46.500000  46.070000  46.099998   6893500  45.108802\n",
      "2014-12-29  46.020000  46.090000  45.599998  45.610001   9701400  44.629340\n",
      "2014-12-30  45.549999  45.660000  45.290001  45.340000   9968400  44.365145\n",
      "2014-12-31  45.450001  45.560001  44.970001  44.970001  13269200  44.003101\n",
      "2015-01-02  45.020000  45.189999  43.970001  44.330002  15070200  43.376862\n",
      "2015-01-05  44.160000  44.250000  43.580002  43.590000  18369400  42.768543\n",
      "2015-01-06  44.060001  44.180000  42.990002  43.139999  19229500  42.327023\n",
      "2015-01-07  43.330002  43.520000  43.009998  43.150002  13502200  42.336836\n",
      "2015-01-08  43.630001  43.939999  43.380001  43.410000  17516900  42.591935\n",
      "2015-01-09  43.980000  44.099998  43.259998  43.389999  15948100  42.572311\n",
      "2015-01-12  43.259998  43.770000  42.860001  43.270000  16050300  42.454574\n",
      "2015-01-13  43.669998  43.950001  42.570000  42.930000  12869300  42.120981\n",
      "...               ...        ...        ...        ...       ...        ...\n",
      "2016-04-18  40.840000  41.250000  40.799999  41.240002   8849300  41.240002\n",
      "2016-04-19  41.410000  41.490002  40.970001  41.060001   9884400  41.060001\n",
      "2016-04-20  41.189999  41.389999  41.080002  41.099998   8481200  41.099998\n",
      "2016-04-21  41.029999  41.299999  40.880001  40.990002  11954100  40.990002\n",
      "2016-04-22  40.790001  41.430000  40.669998  40.700001  15003300  40.700001\n",
      "2016-04-25  40.590000  40.830002  40.470001  40.779999  10876200  40.779999\n",
      "2016-04-26  40.820000  40.849998  40.430000  40.650002   8363800  40.650002\n",
      "2016-04-27  40.509998  41.000000  40.509998  40.849998   8740600  40.849998\n",
      "2016-04-28  40.360001  40.970001  40.169998  40.330002   9024200  40.330002\n",
      "2016-04-29  40.169998  40.169998  39.369999  39.860001  12828700  39.860001\n",
      "2016-05-02  39.900002  40.430000  39.830002  40.299999  10431600  40.299999\n",
      "2016-05-03  40.029999  40.110001  39.529999  39.680000  11366200  39.680000\n",
      "2016-05-04  39.389999  39.570000  39.130001  39.290001   9018300  39.290001\n",
      "2016-05-05  39.439999  39.459999  39.130001  39.230000   8962700  39.230000\n",
      "2016-05-06  38.970001  39.419998  38.970001  39.410000   7578800  39.410000\n",
      "2016-05-09  39.340000  39.730000  39.220001  39.360001   7858100  39.360001\n",
      "2016-05-10  39.580002  40.060001  39.580002  40.020000   9159300  40.020000\n",
      "2016-05-11  39.860001  40.080002  39.639999  39.650002   7016400  39.650002\n",
      "2016-05-12  39.889999  40.029999  39.590000  39.820000  10006700  39.820000\n",
      "2016-05-13  39.779999  40.080002  39.509998  39.610001   9330600  39.610001\n",
      "2016-05-16  39.770000  40.099998  39.459999  39.970001   7754500  39.970001\n",
      "2016-05-17  39.799999  40.020000  39.470001  39.599998   9430300  39.599998\n",
      "2016-05-18  39.590000  39.799999  39.160000  39.470001  10342700  39.470001\n",
      "2016-05-19  39.160000  39.240002  38.560001  38.840000  15103500  38.840000\n",
      "2016-05-20  39.080002  39.580002  38.950001  39.410000  16039200  39.410000\n",
      "2016-05-23  39.310001  39.439999  39.139999  39.180000   8895100  39.180000\n",
      "2016-05-24  39.419998  40.080002  39.250000  39.900002  11326400  39.900002\n",
      "2016-05-25  40.049999  40.290001  40.049999  40.130001   7972200  40.130001\n",
      "2016-05-26  40.110001  40.200001  39.919998  39.950001   7476700  39.950001\n",
      "2016-05-27  39.830002  40.080002  39.799999  40.070000   8159400  40.070000\n",
      "\n",
      "[376 rows x 6 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                 Open       High        Low      Close    Volume  Adj Close\n",
      "Date                                                                       \n",
      "2014-12-01  42.009998  42.380001  42.009998  42.080002  10802400  41.175240\n",
      "2014-12-02  41.900002  42.360001  41.860001  42.180000   9081800  41.273088\n",
      "2014-12-03  41.939999  42.139999  41.639999  42.060001  10326000  41.155669\n",
      "2014-12-04  42.119999  42.119999  41.490002  41.889999   9177100  40.989322\n",
      "2014-12-05  42.020000  42.020000  41.590000  41.930000   8925300  41.028463\n",
      "2014-12-08  41.910000  42.029999  41.330002  41.369999  12766500  40.480502\n",
      "2014-12-09  40.980000  41.930000  40.889999  41.869999  13897500  40.969752\n",
      "2014-12-10  41.700001  41.810001  40.880001  40.919998  12547600  40.040177\n",
      "2014-12-11  41.119999  41.639999  40.709999  40.759998  12395800  39.883617\n",
      "2014-12-12  40.240002  40.779999  39.919998  39.950001  14108200  39.091036\n",
      "2014-12-15  41.209999  41.650002  40.770000  41.110001  22343100  40.226094\n",
      "2014-12-16  40.889999  41.360001  40.610001  40.630001  16424500  39.756415\n",
      "2014-12-17  41.060001  41.630001  40.680000  41.160000  18151000  40.275018\n",
      "2014-12-18  43.830002  45.369999  43.570000  45.349998  54495600  44.374928\n",
      "2014-12-19  45.099998  46.150002  44.980000  46.000000  41782200  45.010954\n",
      "2014-12-22  45.570000  46.049999  45.410000  45.650002  21264400  44.668481\n",
      "2014-12-23  45.529999  46.500000  45.459999  46.009998  14042400  45.020737\n",
      "2014-12-24  46.360001  46.709999  46.150002  46.230000  10238200  45.236008\n",
      "2014-12-26  46.189999  46.500000  46.070000  46.099998   6893500  45.108802\n",
      "2014-12-29  46.020000  46.090000  45.599998  45.610001   9701400  44.629340\n",
      "2014-12-30  45.549999  45.660000  45.290001  45.340000   9968400  44.365145\n",
      "2014-12-31  45.450001  45.560001  44.970001  44.970001  13269200  44.003101\n",
      "2015-01-02  45.020000  45.189999  43.970001  44.330002  15070200  43.376862\n",
      "2015-01-05  44.160000  44.250000  43.580002  43.590000  18369400  42.768543\n",
      "2015-01-06  44.060001  44.180000  42.990002  43.139999  19229500  42.327023\n",
      "2015-01-07  43.330002  43.520000  43.009998  43.150002  13502200  42.336836\n",
      "2015-01-08  43.630001  43.939999  43.380001  43.410000  17516900  42.591935\n",
      "2015-01-09  43.980000  44.099998  43.259998  43.389999  15948100  42.572311\n",
      "2015-01-12  43.259998  43.770000  42.860001  43.270000  16050300  42.454574\n",
      "2015-01-13  43.669998  43.950001  42.570000  42.930000  12869300  42.120981\n",
      "...               ...        ...        ...        ...       ...        ...\n",
      "2016-04-18  40.840000  41.250000  40.799999  41.240002   8849300  41.240002\n",
      "2016-04-19  41.410000  41.490002  40.970001  41.060001   9884400  41.060001\n",
      "2016-04-20  41.189999  41.389999  41.080002  41.099998   8481200  41.099998\n",
      "2016-04-21  41.029999  41.299999  40.880001  40.990002  11954100  40.990002\n",
      "2016-04-22  40.790001  41.430000  40.669998  40.700001  15003300  40.700001\n",
      "2016-04-25  40.590000  40.830002  40.470001  40.779999  10876200  40.779999\n",
      "2016-04-26  40.820000  40.849998  40.430000  40.650002   8363800  40.650002\n",
      "2016-04-27  40.509998  41.000000  40.509998  40.849998   8740600  40.849998\n",
      "2016-04-28  40.360001  40.970001  40.169998  40.330002   9024200  40.330002\n",
      "2016-04-29  40.169998  40.169998  39.369999  39.860001  12828700  39.860001\n",
      "2016-05-02  39.900002  40.430000  39.830002  40.299999  10431600  40.299999\n",
      "2016-05-03  40.029999  40.110001  39.529999  39.680000  11366200  39.680000\n",
      "2016-05-04  39.389999  39.570000  39.130001  39.290001   9018300  39.290001\n",
      "2016-05-05  39.439999  39.459999  39.130001  39.230000   8962700  39.230000\n",
      "2016-05-06  38.970001  39.419998  38.970001  39.410000   7578800  39.410000\n",
      "2016-05-09  39.340000  39.730000  39.220001  39.360001   7858100  39.360001\n",
      "2016-05-10  39.580002  40.060001  39.580002  40.020000   9159300  40.020000\n",
      "2016-05-11  39.860001  40.080002  39.639999  39.650002   7016400  39.650002\n",
      "2016-05-12  39.889999  40.029999  39.590000  39.820000  10006700  39.820000\n",
      "2016-05-13  39.779999  40.080002  39.509998  39.610001   9330600  39.610001\n",
      "2016-05-16  39.770000  40.099998  39.459999  39.970001   7754500  39.970001\n",
      "2016-05-17  39.799999  40.020000  39.470001  39.599998   9430300  39.599998\n",
      "2016-05-18  39.590000  39.799999  39.160000  39.470001  10342700  39.470001\n",
      "2016-05-19  39.160000  39.240002  38.560001  38.840000  15103500  38.840000\n",
      "2016-05-20  39.080002  39.580002  38.950001  39.410000  16039200  39.410000\n",
      "2016-05-23  39.310001  39.439999  39.139999  39.180000   8895100  39.180000\n",
      "2016-05-24  39.419998  40.080002  39.250000  39.900002  11326400  39.900002\n",
      "2016-05-25  40.049999  40.290001  40.049999  40.130001   7972200  40.130001\n",
      "2016-05-26  40.110001  40.200001  39.919998  39.950001   7476700  39.950001\n",
      "2016-05-27  39.830002  40.080002  39.799999  40.070000   8159400  40.070000\n",
      "\n",
      "[376 rows x 6 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                 Open       High        Low      Close    Volume  Adj Close\n",
      "Date                                                                       \n",
      "2014-12-01  42.009998  42.380001  42.009998  42.080002  10802400  41.175240\n",
      "2014-12-02  41.900002  42.360001  41.860001  42.180000   9081800  41.273088\n",
      "2014-12-03  41.939999  42.139999  41.639999  42.060001  10326000  41.155669\n",
      "2014-12-04  42.119999  42.119999  41.490002  41.889999   9177100  40.989322\n",
      "2014-12-05  42.020000  42.020000  41.590000  41.930000   8925300  41.028463\n",
      "2014-12-08  41.910000  42.029999  41.330002  41.369999  12766500  40.480502\n",
      "2014-12-09  40.980000  41.930000  40.889999  41.869999  13897500  40.969752\n",
      "2014-12-10  41.700001  41.810001  40.880001  40.919998  12547600  40.040177\n",
      "2014-12-11  41.119999  41.639999  40.709999  40.759998  12395800  39.883617\n",
      "2014-12-12  40.240002  40.779999  39.919998  39.950001  14108200  39.091036\n",
      "2014-12-15  41.209999  41.650002  40.770000  41.110001  22343100  40.226094\n",
      "2014-12-16  40.889999  41.360001  40.610001  40.630001  16424500  39.756415\n",
      "2014-12-17  41.060001  41.630001  40.680000  41.160000  18151000  40.275018\n",
      "2014-12-18  43.830002  45.369999  43.570000  45.349998  54495600  44.374928\n",
      "2014-12-19  45.099998  46.150002  44.980000  46.000000  41782200  45.010954\n",
      "2014-12-22  45.570000  46.049999  45.410000  45.650002  21264400  44.668481\n",
      "2014-12-23  45.529999  46.500000  45.459999  46.009998  14042400  45.020737\n",
      "2014-12-24  46.360001  46.709999  46.150002  46.230000  10238200  45.236008\n",
      "2014-12-26  46.189999  46.500000  46.070000  46.099998   6893500  45.108802\n",
      "2014-12-29  46.020000  46.090000  45.599998  45.610001   9701400  44.629340\n",
      "2014-12-30  45.549999  45.660000  45.290001  45.340000   9968400  44.365145\n",
      "2014-12-31  45.450001  45.560001  44.970001  44.970001  13269200  44.003101\n",
      "2015-01-02  45.020000  45.189999  43.970001  44.330002  15070200  43.376862\n",
      "2015-01-05  44.160000  44.250000  43.580002  43.590000  18369400  42.768543\n",
      "2015-01-06  44.060001  44.180000  42.990002  43.139999  19229500  42.327023\n",
      "2015-01-07  43.330002  43.520000  43.009998  43.150002  13502200  42.336836\n",
      "2015-01-08  43.630001  43.939999  43.380001  43.410000  17516900  42.591935\n",
      "2015-01-09  43.980000  44.099998  43.259998  43.389999  15948100  42.572311\n",
      "2015-01-12  43.259998  43.770000  42.860001  43.270000  16050300  42.454574\n",
      "2015-01-13  43.669998  43.950001  42.570000  42.930000  12869300  42.120981\n",
      "...               ...        ...        ...        ...       ...        ...\n",
      "2016-04-18  40.840000  41.250000  40.799999  41.240002   8849300  41.240002\n",
      "2016-04-19  41.410000  41.490002  40.970001  41.060001   9884400  41.060001\n",
      "2016-04-20  41.189999  41.389999  41.080002  41.099998   8481200  41.099998\n",
      "2016-04-21  41.029999  41.299999  40.880001  40.990002  11954100  40.990002\n",
      "2016-04-22  40.790001  41.430000  40.669998  40.700001  15003300  40.700001\n",
      "2016-04-25  40.590000  40.830002  40.470001  40.779999  10876200  40.779999\n",
      "2016-04-26  40.820000  40.849998  40.430000  40.650002   8363800  40.650002\n",
      "2016-04-27  40.509998  41.000000  40.509998  40.849998   8740600  40.849998\n",
      "2016-04-28  40.360001  40.970001  40.169998  40.330002   9024200  40.330002\n",
      "2016-04-29  40.169998  40.169998  39.369999  39.860001  12828700  39.860001\n",
      "2016-05-02  39.900002  40.430000  39.830002  40.299999  10431600  40.299999\n",
      "2016-05-03  40.029999  40.110001  39.529999  39.680000  11366200  39.680000\n",
      "2016-05-04  39.389999  39.570000  39.130001  39.290001   9018300  39.290001\n",
      "2016-05-05  39.439999  39.459999  39.130001  39.230000   8962700  39.230000\n",
      "2016-05-06  38.970001  39.419998  38.970001  39.410000   7578800  39.410000\n",
      "2016-05-09  39.340000  39.730000  39.220001  39.360001   7858100  39.360001\n",
      "2016-05-10  39.580002  40.060001  39.580002  40.020000   9159300  40.020000\n",
      "2016-05-11  39.860001  40.080002  39.639999  39.650002   7016400  39.650002\n",
      "2016-05-12  39.889999  40.029999  39.590000  39.820000  10006700  39.820000\n",
      "2016-05-13  39.779999  40.080002  39.509998  39.610001   9330600  39.610001\n",
      "2016-05-16  39.770000  40.099998  39.459999  39.970001   7754500  39.970001\n",
      "2016-05-17  39.799999  40.020000  39.470001  39.599998   9430300  39.599998\n",
      "2016-05-18  39.590000  39.799999  39.160000  39.470001  10342700  39.470001\n",
      "2016-05-19  39.160000  39.240002  38.560001  38.840000  15103500  38.840000\n",
      "2016-05-20  39.080002  39.580002  38.950001  39.410000  16039200  39.410000\n",
      "2016-05-23  39.310001  39.439999  39.139999  39.180000   8895100  39.180000\n",
      "2016-05-24  39.419998  40.080002  39.250000  39.900002  11326400  39.900002\n",
      "2016-05-25  40.049999  40.290001  40.049999  40.130001   7972200  40.130001\n",
      "2016-05-26  40.110001  40.200001  39.919998  39.950001   7476700  39.950001\n",
      "2016-05-27  39.830002  40.080002  39.799999  40.070000   8159400  40.070000\n",
      "\n",
      "[376 rows x 6 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                 Open       High        Low      Close    Volume  Adj Close\n",
      "Date                                                                       \n",
      "2014-12-01  42.009998  42.380001  42.009998  42.080002  10802400  41.175240\n",
      "2014-12-02  41.900002  42.360001  41.860001  42.180000   9081800  41.273088\n",
      "2014-12-03  41.939999  42.139999  41.639999  42.060001  10326000  41.155669\n",
      "2014-12-04  42.119999  42.119999  41.490002  41.889999   9177100  40.989322\n",
      "2014-12-05  42.020000  42.020000  41.590000  41.930000   8925300  41.028463\n",
      "2014-12-08  41.910000  42.029999  41.330002  41.369999  12766500  40.480502\n",
      "2014-12-09  40.980000  41.930000  40.889999  41.869999  13897500  40.969752\n",
      "2014-12-10  41.700001  41.810001  40.880001  40.919998  12547600  40.040177\n",
      "2014-12-11  41.119999  41.639999  40.709999  40.759998  12395800  39.883617\n",
      "2014-12-12  40.240002  40.779999  39.919998  39.950001  14108200  39.091036\n",
      "2014-12-15  41.209999  41.650002  40.770000  41.110001  22343100  40.226094\n",
      "2014-12-16  40.889999  41.360001  40.610001  40.630001  16424500  39.756415\n",
      "2014-12-17  41.060001  41.630001  40.680000  41.160000  18151000  40.275018\n",
      "2014-12-18  43.830002  45.369999  43.570000  45.349998  54495600  44.374928\n",
      "2014-12-19  45.099998  46.150002  44.980000  46.000000  41782200  45.010954\n",
      "2014-12-22  45.570000  46.049999  45.410000  45.650002  21264400  44.668481\n",
      "2014-12-23  45.529999  46.500000  45.459999  46.009998  14042400  45.020737\n",
      "2014-12-24  46.360001  46.709999  46.150002  46.230000  10238200  45.236008\n",
      "2014-12-26  46.189999  46.500000  46.070000  46.099998   6893500  45.108802\n",
      "2014-12-29  46.020000  46.090000  45.599998  45.610001   9701400  44.629340\n",
      "2014-12-30  45.549999  45.660000  45.290001  45.340000   9968400  44.365145\n",
      "2014-12-31  45.450001  45.560001  44.970001  44.970001  13269200  44.003101\n",
      "2015-01-02  45.020000  45.189999  43.970001  44.330002  15070200  43.376862\n",
      "2015-01-05  44.160000  44.250000  43.580002  43.590000  18369400  42.768543\n",
      "2015-01-06  44.060001  44.180000  42.990002  43.139999  19229500  42.327023\n",
      "2015-01-07  43.330002  43.520000  43.009998  43.150002  13502200  42.336836\n",
      "2015-01-08  43.630001  43.939999  43.380001  43.410000  17516900  42.591935\n",
      "2015-01-09  43.980000  44.099998  43.259998  43.389999  15948100  42.572311\n",
      "2015-01-12  43.259998  43.770000  42.860001  43.270000  16050300  42.454574\n",
      "2015-01-13  43.669998  43.950001  42.570000  42.930000  12869300  42.120981\n",
      "...               ...        ...        ...        ...       ...        ...\n",
      "2016-04-18  40.840000  41.250000  40.799999  41.240002   8849300  41.240002\n",
      "2016-04-19  41.410000  41.490002  40.970001  41.060001   9884400  41.060001\n",
      "2016-04-20  41.189999  41.389999  41.080002  41.099998   8481200  41.099998\n",
      "2016-04-21  41.029999  41.299999  40.880001  40.990002  11954100  40.990002\n",
      "2016-04-22  40.790001  41.430000  40.669998  40.700001  15003300  40.700001\n",
      "2016-04-25  40.590000  40.830002  40.470001  40.779999  10876200  40.779999\n",
      "2016-04-26  40.820000  40.849998  40.430000  40.650002   8363800  40.650002\n",
      "2016-04-27  40.509998  41.000000  40.509998  40.849998   8740600  40.849998\n",
      "2016-04-28  40.360001  40.970001  40.169998  40.330002   9024200  40.330002\n",
      "2016-04-29  40.169998  40.169998  39.369999  39.860001  12828700  39.860001\n",
      "2016-05-02  39.900002  40.430000  39.830002  40.299999  10431600  40.299999\n",
      "2016-05-03  40.029999  40.110001  39.529999  39.680000  11366200  39.680000\n",
      "2016-05-04  39.389999  39.570000  39.130001  39.290001   9018300  39.290001\n",
      "2016-05-05  39.439999  39.459999  39.130001  39.230000   8962700  39.230000\n",
      "2016-05-06  38.970001  39.419998  38.970001  39.410000   7578800  39.410000\n",
      "2016-05-09  39.340000  39.730000  39.220001  39.360001   7858100  39.360001\n",
      "2016-05-10  39.580002  40.060001  39.580002  40.020000   9159300  40.020000\n",
      "2016-05-11  39.860001  40.080002  39.639999  39.650002   7016400  39.650002\n",
      "2016-05-12  39.889999  40.029999  39.590000  39.820000  10006700  39.820000\n",
      "2016-05-13  39.779999  40.080002  39.509998  39.610001   9330600  39.610001\n",
      "2016-05-16  39.770000  40.099998  39.459999  39.970001   7754500  39.970001\n",
      "2016-05-17  39.799999  40.020000  39.470001  39.599998   9430300  39.599998\n",
      "2016-05-18  39.590000  39.799999  39.160000  39.470001  10342700  39.470001\n",
      "2016-05-19  39.160000  39.240002  38.560001  38.840000  15103500  38.840000\n",
      "2016-05-20  39.080002  39.580002  38.950001  39.410000  16039200  39.410000\n",
      "2016-05-23  39.310001  39.439999  39.139999  39.180000   8895100  39.180000\n",
      "2016-05-24  39.419998  40.080002  39.250000  39.900002  11326400  39.900002\n",
      "2016-05-25  40.049999  40.290001  40.049999  40.130001   7972200  40.130001\n",
      "2016-05-26  40.110001  40.200001  39.919998  39.950001   7476700  39.950001\n",
      "2016-05-27  39.830002  40.080002  39.799999  40.070000   8159400  40.070000\n",
      "\n",
      "[376 rows x 6 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                 Open       High        Low      Close    Volume  Adj Close\n",
      "Date                                                                       \n",
      "2014-12-01  42.009998  42.380001  42.009998  42.080002  10802400  41.175240\n",
      "2014-12-02  41.900002  42.360001  41.860001  42.180000   9081800  41.273088\n",
      "2014-12-03  41.939999  42.139999  41.639999  42.060001  10326000  41.155669\n",
      "2014-12-04  42.119999  42.119999  41.490002  41.889999   9177100  40.989322\n",
      "2014-12-05  42.020000  42.020000  41.590000  41.930000   8925300  41.028463\n",
      "2014-12-08  41.910000  42.029999  41.330002  41.369999  12766500  40.480502\n",
      "2014-12-09  40.980000  41.930000  40.889999  41.869999  13897500  40.969752\n",
      "2014-12-10  41.700001  41.810001  40.880001  40.919998  12547600  40.040177\n",
      "2014-12-11  41.119999  41.639999  40.709999  40.759998  12395800  39.883617\n",
      "2014-12-12  40.240002  40.779999  39.919998  39.950001  14108200  39.091036\n",
      "2014-12-15  41.209999  41.650002  40.770000  41.110001  22343100  40.226094\n",
      "2014-12-16  40.889999  41.360001  40.610001  40.630001  16424500  39.756415\n",
      "2014-12-17  41.060001  41.630001  40.680000  41.160000  18151000  40.275018\n",
      "2014-12-18  43.830002  45.369999  43.570000  45.349998  54495600  44.374928\n",
      "2014-12-19  45.099998  46.150002  44.980000  46.000000  41782200  45.010954\n",
      "2014-12-22  45.570000  46.049999  45.410000  45.650002  21264400  44.668481\n",
      "2014-12-23  45.529999  46.500000  45.459999  46.009998  14042400  45.020737\n",
      "2014-12-24  46.360001  46.709999  46.150002  46.230000  10238200  45.236008\n",
      "2014-12-26  46.189999  46.500000  46.070000  46.099998   6893500  45.108802\n",
      "2014-12-29  46.020000  46.090000  45.599998  45.610001   9701400  44.629340\n",
      "2014-12-30  45.549999  45.660000  45.290001  45.340000   9968400  44.365145\n",
      "2014-12-31  45.450001  45.560001  44.970001  44.970001  13269200  44.003101\n",
      "2015-01-02  45.020000  45.189999  43.970001  44.330002  15070200  43.376862\n",
      "2015-01-05  44.160000  44.250000  43.580002  43.590000  18369400  42.768543\n",
      "2015-01-06  44.060001  44.180000  42.990002  43.139999  19229500  42.327023\n",
      "2015-01-07  43.330002  43.520000  43.009998  43.150002  13502200  42.336836\n",
      "2015-01-08  43.630001  43.939999  43.380001  43.410000  17516900  42.591935\n",
      "2015-01-09  43.980000  44.099998  43.259998  43.389999  15948100  42.572311\n",
      "2015-01-12  43.259998  43.770000  42.860001  43.270000  16050300  42.454574\n",
      "2015-01-13  43.669998  43.950001  42.570000  42.930000  12869300  42.120981\n",
      "...               ...        ...        ...        ...       ...        ...\n",
      "2016-04-18  40.840000  41.250000  40.799999  41.240002   8849300  41.240002\n",
      "2016-04-19  41.410000  41.490002  40.970001  41.060001   9884400  41.060001\n",
      "2016-04-20  41.189999  41.389999  41.080002  41.099998   8481200  41.099998\n",
      "2016-04-21  41.029999  41.299999  40.880001  40.990002  11954100  40.990002\n",
      "2016-04-22  40.790001  41.430000  40.669998  40.700001  15003300  40.700001\n",
      "2016-04-25  40.590000  40.830002  40.470001  40.779999  10876200  40.779999\n",
      "2016-04-26  40.820000  40.849998  40.430000  40.650002   8363800  40.650002\n",
      "2016-04-27  40.509998  41.000000  40.509998  40.849998   8740600  40.849998\n",
      "2016-04-28  40.360001  40.970001  40.169998  40.330002   9024200  40.330002\n",
      "2016-04-29  40.169998  40.169998  39.369999  39.860001  12828700  39.860001\n",
      "2016-05-02  39.900002  40.430000  39.830002  40.299999  10431600  40.299999\n",
      "2016-05-03  40.029999  40.110001  39.529999  39.680000  11366200  39.680000\n",
      "2016-05-04  39.389999  39.570000  39.130001  39.290001   9018300  39.290001\n",
      "2016-05-05  39.439999  39.459999  39.130001  39.230000   8962700  39.230000\n",
      "2016-05-06  38.970001  39.419998  38.970001  39.410000   7578800  39.410000\n",
      "2016-05-09  39.340000  39.730000  39.220001  39.360001   7858100  39.360001\n",
      "2016-05-10  39.580002  40.060001  39.580002  40.020000   9159300  40.020000\n",
      "2016-05-11  39.860001  40.080002  39.639999  39.650002   7016400  39.650002\n",
      "2016-05-12  39.889999  40.029999  39.590000  39.820000  10006700  39.820000\n",
      "2016-05-13  39.779999  40.080002  39.509998  39.610001   9330600  39.610001\n",
      "2016-05-16  39.770000  40.099998  39.459999  39.970001   7754500  39.970001\n",
      "2016-05-17  39.799999  40.020000  39.470001  39.599998   9430300  39.599998\n",
      "2016-05-18  39.590000  39.799999  39.160000  39.470001  10342700  39.470001\n",
      "2016-05-19  39.160000  39.240002  38.560001  38.840000  15103500  38.840000\n",
      "2016-05-20  39.080002  39.580002  38.950001  39.410000  16039200  39.410000\n",
      "2016-05-23  39.310001  39.439999  39.139999  39.180000   8895100  39.180000\n",
      "2016-05-24  39.419998  40.080002  39.250000  39.900002  11326400  39.900002\n",
      "2016-05-25  40.049999  40.290001  40.049999  40.130001   7972200  40.130001\n",
      "2016-05-26  40.110001  40.200001  39.919998  39.950001   7476700  39.950001\n",
      "2016-05-27  39.830002  40.080002  39.799999  40.070000   8159400  40.070000\n",
      "\n",
      "[376 rows x 6 columns]\n",
      "                   IBM       MSFT       ORCL        TSLA       YELP\n",
      "Date                                                               \n",
      "2014-12-01  153.369884  46.667637  41.175240  231.639999  55.130001\n",
      "2014-12-02  154.442737  46.514062  41.273088  231.429993  55.169998\n",
      "2014-12-03  156.199177  46.149324  41.155669  229.300003  54.770000\n",
      "2014-12-04  155.752946  46.878804  40.989322  228.279999  55.139999\n",
      "2014-12-05  155.012397  46.475667  41.028463  223.710007  53.840000\n",
      "2014-12-08  153.673706  45.784582  40.480502  214.360001  51.520000\n",
      "2014-12-09  154.746560  45.678998  40.969752  216.889999  52.730000\n",
      "2014-12-10  152.391979  45.016707  40.040177  209.839996  51.959999\n",
      "2014-12-11  152.923668  45.275862  39.883617  208.880005  52.450001\n",
      "2014-12-12  147.521445  45.064699  39.091036  207.000000  52.700001\n",
      "2014-12-15  145.318776  44.795940  40.226094  204.039993  53.259998\n",
      "2014-12-16  143.752232  43.346576  39.756415  197.809998  50.040001\n",
      "2014-12-17  144.245922  43.903288  40.275018  205.820007  51.900002\n",
      "2014-12-18  149.705108  45.611810  44.374928  218.259995  52.490002\n",
      "2014-12-19  150.493131  45.746187  45.010954  219.289993  54.590000\n",
      "2014-12-22  153.274950  46.053337  44.668481  222.600006  53.000000\n",
      "2014-12-23  154.034492  46.504465  45.020737  220.970001  53.360001\n",
      "2014-12-24  153.635736  46.206912  45.236008  222.259995  53.000000\n",
      "2014-12-26  154.129426  45.957354  45.108802  227.820007  52.939999\n",
      "2014-12-29  152.391979  45.544621  44.629340  225.710007  53.009998\n",
      "2014-12-30  151.955252  45.131887  44.365145  222.229996  54.240002\n",
      "2014-12-31  152.325526  44.584776  44.003101  222.410004  54.730000\n",
      "2015-01-02  153.863588  44.882326  43.376862  219.309998  55.150002\n",
      "2015-01-05  151.442555  44.469596  42.768543  210.089996  52.529999\n",
      "2015-01-06  148.176550  43.816902  42.327023  211.279999  52.439999\n",
      "2015-01-07  147.208134  44.373609  42.336836  210.949997  52.209999\n",
      "2015-01-08  150.407687  45.678998  42.591935  210.619995  53.830002\n",
      "2015-01-09  151.062791  45.295059  42.572311  206.660004  56.070000\n",
      "2015-01-12  148.527832  44.728751  42.454574  202.210007  54.020000\n",
      "2015-01-13  148.879114  44.498390  42.120981  204.250000  53.180000\n",
      "...                ...        ...        ...         ...        ...\n",
      "2016-04-18  151.072077  56.067840  41.240002  253.880005  21.340000\n",
      "2016-04-19  142.623610  55.998326  41.060001  247.369995  20.780001\n",
      "2016-04-20  144.713443  55.203884  41.099998  249.970001  21.150000\n",
      "2016-04-21  147.872955  55.392563  40.990002  248.289993  21.490000\n",
      "2016-04-22  147.080598  51.420346  40.700001  253.750000  21.520000\n",
      "2016-04-25  147.387633  51.748056  40.779999  251.820007  21.139999\n",
      "2016-04-26  147.655056  51.082707  40.650002  253.740005  21.150000\n",
      "2016-04-27  149.031770  50.586180  40.849998  251.470001  21.080000\n",
      "2016-04-28  145.664274  49.553407  40.330002  247.710007  21.010000\n",
      "2016-04-29  144.545070  49.523612  39.860001  240.759995  21.000000\n",
      "2016-05-02  143.881476  50.258474  40.299999  241.800003  21.510000\n",
      "2016-05-03  142.752373  49.434237  39.680000  232.320007  22.150000\n",
      "2016-05-04  142.871221  49.523612  39.290001  222.559998  21.639999\n",
      "2016-05-05  145.070003  49.593126  39.230000  211.529999  21.420000\n",
      "2016-05-06  147.289993  50.040001  39.410000  214.929993  26.500000\n",
      "2016-05-09  147.339996  49.722224  39.360001  208.919998  25.840000\n",
      "2016-05-10  149.970001  50.665626  40.020000  208.690002  26.320000\n",
      "2016-05-11  148.949997  50.695417  39.650002  208.960007  25.309999\n",
      "2016-05-12  148.839996  51.152221  39.820000  207.279999  24.500000\n",
      "2016-05-13  147.720001  50.725211  39.610001  207.610001  25.320000\n",
      "2016-05-16  149.460007  51.470002  39.970001  208.289993  25.180000\n",
      "2016-05-17  148.000000  50.509998  39.599998  204.660004  25.209999\n",
      "2016-05-18  147.339996  50.810001  39.470001  211.169998  24.980000\n",
      "2016-05-19  144.929993  50.320000  38.840000  215.210007  24.700001\n",
      "2016-05-20  147.250000  50.619999  39.410000  220.279999  25.200001\n",
      "2016-05-23  146.770004  50.029999  39.180000  216.220001  24.900000\n",
      "2016-05-24  148.309998  51.590000  39.900002  217.910004  25.379999\n",
      "2016-05-25  151.690002  52.119999  40.130001  219.580002  25.700001\n",
      "2016-05-26  152.440002  51.889999  39.950001  225.119995  25.660000\n",
      "2016-05-27  152.839996  52.320000  40.070000  223.039993  25.860001\n",
      "\n",
      "[376 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.data import DataReader\n",
    "from datetime import datetime\n",
    "\n",
    "goog = DataReader(\"GOOG\",  \"yahoo\", datetime(2000,1,1), datetime(2012,1,1))\n",
    "print goog[:100][\"Adj Close\"]\n",
    "\n",
    "symbols_list = ['ORCL', 'TSLA', 'IBM','YELP', 'MSFT']\n",
    "d = {}\n",
    "for ticker in symbols_list:\n",
    "    d[ticker] = DataReader(ticker, \"yahoo\", '2014-12-01')\n",
    "    print type(d['ORCL'])\n",
    "    print( d['ORCL'] )\n",
    "pan = pd.Panel(d)\n",
    "df1 = pan.minor_xs('Adj Close')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection\n",
    "\n",
    "- AdjClose_sp  \n",
    "- AdjClose_nasdaq  \n",
    "- AdjClose_djia  \n",
    "- AdjClose_frankfurt  \n",
    "- AdjClose_london  \n",
    "- AdjClose_paris  \n",
    "- AdjClose_nikkei  \n",
    "- AdjClose_hkong  \n",
    "- AdjClose_australia  \n",
    "\n",
    "To account for time variations, add the following basic financial metrics:\n",
    "\n",
    "**1) Days Returns:** percentage difference of Adjusted Close Price of $i^{th}$ day  compared to $(i-1)^{th}$ day. \n",
    "\n",
    "$Return_i=\\dfrac{AdjClose_i–AdjClose_{i−1}}{AdjClose_{i−1}}$\n",
    "\n",
    "**2) Multiple Day Returns:** percentage difference of the *Adjusted Close Price* of $i^{th}$ day  compared to $(i-\\delta)^{th}$ day. Example: 3-days Return is the percentage difference of Adjusted Close Price of today compared to the one of 3 days ago.\n",
    "\n",
    "$Return_{\\delta}=\\dfrac{AdjClose_i–AdjClose_{i−\\delta}}{AdjClose_{i−\\delta}}$\n",
    "\n",
    "**3) Moving Average Returns:** average returns over last $\\delta$ days. Example: 3-day return is the percentage difference of the *Adjusted Close Price* of today compared to the one of 3 days ago.\n",
    "\n",
    "$MovingAverage_{\\delta}=\\dfrac{Return_i+Return_{i−1}+Return_{i−2}+…+Return_{i−\\delta}}{\\delta}$\n",
    "\n",
    "**4) Time Lagged Returns:** shift the daily returns *n* days backwards. Example: if n =  1 todays’ Return becomes yesterdays’ Return.\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "- Start with 8 basic predictors: (the Adjusted Close Price of the 8 world major stock indices) + 1 output/predictor (Adjusted Close Price of S&P 500). \n",
    "\n",
    "- The daily returns of each predictor.\n",
    "\n",
    "- Add features to the DataFrame using the 4 financial metrics. With values for $n$ and $\\delta$ to generate additional features.\n",
    "\n",
    "- Remove the original Adjusted Close Price, ending up with a perfectly scaled dataset. \n",
    "\n",
    "- Notice that a bunch of missing values are automatically produced. To make this point clear let’s walk through a practical example:\n",
    "\n",
    "What happens you compute the 3-day-Moving Average on the Daily Returns column? Pandas is going to replace today’s return with the average of the returns of the last 3 days. Now let’s suppose that the first entry in the dataframe corresponds to 20 April 2014. There is going to be no 3-day-Moving Average for 20 April 2014 as there are no 3 previous days. The same for 21 and 22 April 2014. Actually the first non-missing day is going to be 23 April 2014 as it would be possible to compute the average of daily returns on the 3 previous days. Notice that the same issue (with slightly different results) rises with the other financial metrics are taken into account.\n",
    "\n",
    "Given the AdjClose and Returns, addFeatures() returns delta-Multiple Day Returns and delta-Returns Moving Average. This function is called for several deltas inside applyRollMeanDelayedReturns()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addFeatures(dataframe, adjclose, returns, n):\n",
    "    \"\"\"\n",
    "    operates on two columns of dataframe:\n",
    "    - n >= 2\n",
    "    - given Return_* computes the return of day i respect to day i-n. \n",
    "    - given AdjClose_* computes its moving average on n days\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    return_n = adjclose[9:] + \"Time\" + str(n)\n",
    "    dataframe[return_n] = dataframe[adjclose].pct_change(n)\n",
    "    \n",
    "    roll_n = returns[7:] + \"RolMean\" + str(n)\n",
    "    dataframe[roll_n] = pd.rolling_mean(dataframe[returns], n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the list of datasets and the range of deltas to explore, applyRollMeanDelayedReturns() adds features to each dataset and returns the augmented list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def applyRollMeanDelayedReturns(datasets, delta):\n",
    "    \"\"\"\n",
    "    applies rolling mean and delayed returns to each dataframe in the list\n",
    "    \"\"\"\n",
    "    for dataset in datasets:\n",
    "        columns = dataset.columns    \n",
    "        adjclose = columns[-2]\n",
    "        returns = columns[-1]\n",
    "        for n in delta:\n",
    "            addFeatures(dataset, adjclose, returns, n)\n",
    "    \n",
    "    return datasets    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "– mergeDataframes() is fundamental as it takes the list of augmented datasets produced by applyRollMeanDelayedReturns() and merges all of them in the finance dataframe applying a time cut at the beginning of the series (all data after 1993 – I decided to implement this time cut as Australia ASX-200 data is not available before that time) and selecting only the relevant columns out of each dataframe. This is the step in which we get rid of all the Open, High, Low, Close, Volume, AdjClose columns in each dataset and keep only the Daily Returns, delta-Multiple Day Returns and delta-Returns Moving Average previously created.\n",
    "\n",
    "I want to stress the specific merging Pandas command. This step is quite tricky as I’m concatenating dataframes by date index. The issue arising is that markets all over the world have not the same trading days due basically to different national holidays. So there is going to be an unavoidable annoying mismatch between dates. I faced the issue in the following way:\n",
    "\n",
    "Perform an OUTER JOIN of all the predictors. This command generates a UNION of all the columns, thus creating a bunch of NAs. I afterwards imputed them by linear interpolation. Let’s call the result of this operation PREDICTORS.\n",
    "Perform a S&P LEFT JOIN PREDICTORS. This line shrinks PREDICTORS to match S&P date index. Thus no additional NA will be created in the output dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-78105cc35a9c>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-78105cc35a9c>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    subset = []tion\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def mergeDataframes(datasets, index, cut):\n",
    "    \"\"\"\n",
    "    merges datasets in the list \n",
    "    \"\"\"\n",
    "    subset = []tion\n",
    "    subset = [dataset.iloc[:, index:] for dataset in datasets[1:]]\n",
    "    \n",
    "    first = subset[0].join(subset[1:], how = 'outer')\n",
    "    finance = datasets[0].iloc[:, index:].join(first, how = 'left') \n",
    "    finance = finance[finance.index > cut]\n",
    "    return finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyTimeLag(dataset, lags, delta):\n",
    "    \"\"\"\n",
    "    apply time lag to return columns selected according  to delta.\n",
    "    Days to lag are contained in the lads list passed as argument.\n",
    "    Returns a NaN free dataset obtained cutting the lagged dataset\n",
    "    at head and tail\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset.Return_Out = dataset.Return_Out.shift(-1)\n",
    "    maxLag = max(lags)\n",
    "\n",
    "    columns = dataset.columns[::(2*max(delta)-1)]\n",
    "    for column in columns:\n",
    "        for lag in lags:\n",
    "            newcolumn = column + str(lag)\n",
    "            dataset[newcolumn] = dataset[column].shift(lag)\n",
    "\n",
    "    return dataset.iloc[maxLag:-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def applyTimeLag(dataset, lags, delta):\n",
    "    \"\"\"\n",
    "    apply time lag to return columns selected according  to delta.\n",
    "    Days to lag are contained in the lads list passed as argument.\n",
    "    Returns a NaN free dataset obtained cutting the lagged dataset\n",
    "    at head and tail\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset.Return_Out = dataset.Return_Out.shift(-1)\n",
    "    maxLag = max(lags)\n",
    "\n",
    "    columns = dataset.columns[::(2*max(delta)-1)]\n",
    "    for column in columns:\n",
    "        for lag in lags:\n",
    "            newcolumn = column + str(lag)\n",
    "            dataset[newcolumn] = dataset[column].shift(lag)\n",
    "\n",
    "    return dataset.iloc[maxLag:-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### performClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performClassification(X_train, y_train, X_test, y_test, method, parameters, fout, savemodel):\n",
    "    \"\"\"\n",
    "    performs classification on daily returns using several algorithms (method).\n",
    "    method --> string algorithm\n",
    "    parameters --> list of parameters passed to the classifier (if any)\n",
    "    fout --> string with name of stock to be predicted\n",
    "    savemodel --> boolean. If TRUE saves the model to pickle file\n",
    "    \"\"\"\n",
    "   \n",
    "    if method == 'RF':   \n",
    "        return performRFClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel)\n",
    "        \n",
    "    elif method == 'KNN':\n",
    "        return performKNNClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel)\n",
    "    \n",
    "    elif method == 'SVM':   \n",
    "        return performSVMClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel)\n",
    "    \n",
    "    elif method == 'ADA':\n",
    "        return performAdaBoostClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel)\n",
    "    \n",
    "    elif method == 'GTB': \n",
    "        return performGTBClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel)\n",
    "\n",
    "    elif method == 'QDA': \n",
    "        return performQDAClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performRFClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel):\n",
    "    \"\"\"\n",
    "    Random Forest Binary Classification\n",
    "    \"\"\"\n",
    "    clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    if savemodel == True:\n",
    "        fname_out = '{}-{}.pickle'.format(fout, datetime.now())\n",
    "        with open(fname_out, 'wb') as f:\n",
    "            cPickle.dump(clf, f, -1)    \n",
    "    \n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performKNNClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel):\n",
    "    \"\"\"\n",
    "    KNN binary Classification\n",
    "    \"\"\"\n",
    "    clf = neighbors.KNeighborsClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    if savemodel == True:\n",
    "        fname_out = '{}-{}.pickle'.format(fout, datetime.now())\n",
    "        with open(fname_out, 'wb') as f:\n",
    "            cPickle.dump(clf, f, -1)    \n",
    "    \n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performSVMClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel):\n",
    "    \"\"\"\n",
    "    SVM binary Classification\n",
    "    \"\"\"\n",
    "    c = parameters[0]\n",
    "    g =  parameters[1]\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    if savemodel == True:\n",
    "        fname_out = '{}-{}.pickle'.format(fout, datetime.now())\n",
    "        with open(fname_out, 'wb') as f:\n",
    "            cPickle.dump(clf, f, -1)    \n",
    "    \n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performAdaBoostClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel):\n",
    "    \"\"\"\n",
    "    Ada Boosting binary Classification\n",
    "    \"\"\"\n",
    "    n = parameters[0]\n",
    "    l =  parameters[1]\n",
    "    clf = AdaBoostClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    if savemodel == True:\n",
    "        fname_out = '{}-{}.pickle'.format(fout, datetime.now())\n",
    "        with open(fname_out, 'wb') as f:\n",
    "            cPickle.dump(clf, f, -1)    \n",
    "    \n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performGTBClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel):\n",
    "    \"\"\"\n",
    "    Gradient Tree Boosting binary Classification\n",
    "    \"\"\"\n",
    "    clf = GradientBoostingClassifier(n_estimators=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    if savemodel == True:\n",
    "        fname_out = '{}-{}.pickle'.format(fout, datetime.now())\n",
    "        with open(fname_out, 'wb') as f:\n",
    "            cPickle.dump(clf, f, -1)    \n",
    "    \n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performQDAClass(X_train, y_train, X_test, y_test, parameters, fout, savemodel):\n",
    "    \"\"\"\n",
    "    Quadratic Discriminant Analysis binary Classification\n",
    "    \"\"\"\n",
    "    def replaceTiny(x):\n",
    "        if (abs(x) < 0.0001):\n",
    "            x = 0.0001\n",
    "    \n",
    "    X_train = X_train.apply(replaceTiny)\n",
    "    X_test = X_test.apply(replaceTiny)\n",
    "    \n",
    "    clf = QDA()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    if savemodel == True:\n",
    "        fname_out = '{}-{}.pickle'.format(fout, datetime.now())\n",
    "        with open(fname_out, 'wb') as f:\n",
    "            cPickle.dump(clf, f, -1)    \n",
    "    \n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performFeatureSelection(maxdeltas, maxlags, fout, cut, start_test, path_datasets, savemodel, method, folds, parameters):\n",
    "    \"\"\"\n",
    "    Performs Feature selection for a specific algorithm\n",
    "    \"\"\"\n",
    "    \n",
    "    for maxlag in range(3, maxlags + 2):\n",
    "        lags = range(2, maxlag) \n",
    "        print ''\n",
    "        print '============================================================='\n",
    "        print 'Maximum time lag applied', max(lags)\n",
    "        print ''\n",
    "        for maxdelta in range(3, maxdeltas + 2):\n",
    "            datasets = loadDatasets(path_datasets, fout)\n",
    "            delta = range(2, maxdelta) \n",
    "            print 'Delta days accounted: ', max(delta)\n",
    "            datasets = applyRollMeanDelayedReturns(datasets, delta)\n",
    "            finance = mergeDataframes(datasets, 6, cut)\n",
    "            print 'Size of data frame: ', finance.shape\n",
    "            print 'Number of NaN after merging: ', count_missing(finance)\n",
    "            finance = finance.interpolate(method='linear')\n",
    "            print 'Number of NaN after time interpolation: ', count_missing(finance)\n",
    "            finance = finance.fillna(finance.mean())\n",
    "            print 'Number of NaN after mean interpolation: ', count_missing(finance)    \n",
    "            finance = applyTimeLag(finance, lags, delta)\n",
    "            print 'Number of NaN after temporal shifting: ', count_missing(finance)\n",
    "            print 'Size of data frame after feature creation: ', finance.shape\n",
    "            X_train, y_train, X_test, y_test  = prepareDataForClassification(finance, start_test)\n",
    "            \n",
    "            print performCV(X_train, y_train, folds, method, parameters, fout, savemodel)\n",
    "            print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually we decided that our best combinations is the following:\n",
    "\n",
    "Algorithm: Random Forests (n_estimators = 100)  \n",
    "Features: n = 9 / delta  = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.6tf1.3keras]",
   "language": "python",
   "name": "conda-env-py3.6tf1.3keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
