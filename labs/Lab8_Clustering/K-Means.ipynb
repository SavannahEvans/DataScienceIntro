{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### K-Means \n",
    "\n",
    "Jay Urbain, PhD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: K Means\n",
    "# -------------\n",
    "# K-Means is an algorithm that takes in a dataset and a constant\n",
    "# k and returns k centroids (which define clusters of data in the\n",
    "# dataset which are similar to one another).\n",
    "def kmeans(dataSet, k):\n",
    "\n",
    "    # Initialize centroids randomly\n",
    "    numFeatures = dataSet.getNumFeatures()\n",
    "    centroids = getRandomCentroids(numFeatures, k)\n",
    "    \n",
    "    # Initialize book keeping vars.\n",
    "    iterations = 0\n",
    "    oldCentroids = None\n",
    "    \n",
    "    # Run the main k-means algorithm\n",
    "    while not shouldStop(oldCentroids, centroids, iterations):\n",
    "        # Save old centroids for convergence test. Book keeping.\n",
    "        oldCentroids = centroids\n",
    "        iterations += 1\n",
    "        \n",
    "        # Assign labels to each datapoint based on centroids\n",
    "        labels = getLabels(dataSet, centroids)\n",
    "        \n",
    "        # Assign centroids based on datapoint labels\n",
    "        centroids = getCentroids(dataSet, labels, k)\n",
    "        \n",
    "    # We can get the labels too by calling getLabels(dataSet, centroids)\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Should Stop\n",
    "# -------------\n",
    "# Returns True or False if k-means is done. K-means terminates either\n",
    "# because it has run a maximum number of iterations OR the centroids\n",
    "# stop changing.\n",
    "def shouldStop(oldCentroids, centroids, iterations):\n",
    "    if iterations > MAX_ITERATIONS: return True\n",
    "    return oldCentroids == centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-3-05bf158320cb>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-05bf158320cb>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    # Make that centroid the element's label.\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# Function: Get Labels\n",
    "# -------------\n",
    "# Returns a label for each piece of data in the dataset. \n",
    "def getLabels(dataSet, centroids):\n",
    "    # For each element in the dataset, chose the closest centroid. \n",
    "    # Make that centroid the element's label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Get Centroids\n",
    "# -------------\n",
    "# Returns k random centroids, each of dimension n.\n",
    "def getCentroids(dataSet, labels, k):\n",
    "    # Each centroid is the geometric mean of the points that\n",
    "    # have that centroid's label. Important: If a centroid is empty (no points have\n",
    "    # that centroid's label) you should randomly re-initialize it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note: You might be tempted to calculate the distance between two points manually, by looping over values. This will work, but it will lead to a slow k-means! And a slow k-means will mean that you have to wait longer to test and debug your solution.\n",
    "\n",
    "Let's define three vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5]\n",
    "y = np.array([8, 8, 8, 8, 8])\n",
    "z = np.ones((5, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the distance between x and y we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sum((x - y) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the distance between all the length 5 vectors in z and x we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(((z-x)**2).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "def cluster_points(X, mu):\n",
    "    clusters  = {}\n",
    "    for x in X:\n",
    "        bestmukey = min([(i[0], np.linalg.norm(x-mu[i[0]])) \\\n",
    "                    for i in enumerate(mu)], key=lambda t:t[1])[0]\n",
    "        try:\n",
    "            clusters[bestmukey].append(x)\n",
    "        except KeyError:\n",
    "            clusters[bestmukey] = [x]\n",
    "    return clusters\n",
    "\n",
    " \n",
    "def reevaluate_centers(mu, clusters):\n",
    "    newmu = []\n",
    "    keys = sorted(clusters.keys())\n",
    "    for k in keys:\n",
    "        newmu.append(np.mean(clusters[k], axis = 0))\n",
    "    return newmu\n",
    " \n",
    "def has_converged(mu, oldmu):\n",
    "    return (set([tuple(a) for a in mu]) == set([tuple(a) for a in oldmu]) )\n",
    "\n",
    "def find_centers(X, K):\n",
    "    # Initialize to K random centers\n",
    "    oldmu = random.sample(X, K)\n",
    "    mu = random.sample(X, K)\n",
    "    while not has_converged(mu, oldmu):\n",
    "        oldmu = mu\n",
    "        # Assign all points in X to clusters\n",
    "        clusters = cluster_points(X, mu)\n",
    "        # Reevaluate centers\n",
    "        mu = reevaluate_centers(oldmu, clusters)\n",
    "    return(mu, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    " \n",
    "def init_board(N):\n",
    "    X = np.array([(random.uniform(-1, 1), random.uniform(-1, 1)) for i in range(N)])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_board_gauss(N, k):\n",
    "    n = float(N)/k\n",
    "    X = []\n",
    "    for i in range(k):\n",
    "        c = (random.uniform(-1, 1), random.uniform(-1, 1))\n",
    "        s = random.uniform(0.05,0.5)\n",
    "        x = []\n",
    "        while len(x) < n:\n",
    "            a, b = np.array([np.random.normal(c[0], s), np.random.normal(c[1], s)])\n",
    "            # Continue drawing points from the distribution in the range [-1,1]\n",
    "            if abs(a) < 1 and abs(b) < 1:\n",
    "                x.append([a,b])\n",
    "        X.extend(x)\n",
    "    X = np.array(X)[:N]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = init_board_gauss(200,3) # 7 iterations are needed to find the 3 centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# kmeans clustering algorithm\n",
    "# data = set of data points\n",
    "# k = number of clusters\n",
    "# c = initial list of centroids (if provided)\n",
    "#\n",
    "def kmeans(data, k, c):\n",
    "    centroids = []\n",
    "\n",
    "    centroids = randomize_centroids(data, centroids, k)  \n",
    "\n",
    "    old_centroids = [[] for i in range(k)] \n",
    "\n",
    "    iterations = 0\n",
    "    while not (has_converged(centroids, old_centroids, iterations)):\n",
    "        iterations += 1\n",
    "\n",
    "        clusters = [[] for i in range(k)]\n",
    "\n",
    "        # assign data points to clusters\n",
    "        clusters = euclidean_dist(data, centroids, clusters)\n",
    "\n",
    "        # recalculate centroids\n",
    "        index = 0\n",
    "        for cluster in clusters:\n",
    "            old_centroids[index] = centroids[index]\n",
    "            centroids[index] = np.mean(cluster, axis=0).tolist()\n",
    "            index += 1\n",
    "\n",
    "\n",
    "    print(\"The total number of data instances is: \" + str(len(data)))\n",
    "    print(\"The total number of iterations necessary is: \" + str(iterations))\n",
    "    print(\"The means of each cluster are: \" + str(centroids))\n",
    "    print(\"The clusters are as follows:\")\n",
    "    for cluster in clusters:\n",
    "        print(\"Cluster with a size of \" + str(len(cluster)) + \" starts here:\")\n",
    "        print(np.array(cluster).tolist())\n",
    "        print(\"Cluster ends here.\")\n",
    "\n",
    "    return\n",
    "\n",
    "# Calculates euclidean distance between\n",
    "# a data point and all the available cluster\n",
    "# centroids.      \n",
    "def euclidean_dist(data, centroids, clusters):\n",
    "    for instance in data:  \n",
    "        # Find which centroid is the closest\n",
    "        # to the given data point.\n",
    "        mu_index = min([(i[0], np.linalg.norm(instance-centroids[i[0]])) \\\n",
    "                            for i in enumerate(centroids)], key=lambda t:t[1])[0]\n",
    "        try:\n",
    "            clusters[mu_index].append(instance)\n",
    "        except KeyError:\n",
    "            clusters[mu_index] = [instance]\n",
    "\n",
    "    # If any cluster is empty then assign one point\n",
    "    # from data set randomly so as to not have empty\n",
    "    # clusters and 0 means.        \n",
    "    for cluster in clusters:\n",
    "        if not cluster:\n",
    "            cluster.append(data[np.random.randint(0, len(data), size=1)].flatten().tolist())\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# randomize initial centroids\n",
    "def randomize_centroids(data, centroids, k):\n",
    "    for cluster in range(0, k):\n",
    "        centroids.append(data[np.random.randint(0, len(data), size=1)].flatten().tolist())\n",
    "    return centroids\n",
    "\n",
    "\n",
    "# check if clusters have converged    \n",
    "def has_converged(centroids, old_centroids, iterations):\n",
    "    MAX_ITERATIONS = 1000\n",
    "    if iterations > MAX_ITERATIONS:\n",
    "        return True\n",
    "    return old_centroids == centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: K Means\n",
    "# -------------\n",
    "# K-Means is an algorithm that takes in a dataset and a constant\n",
    "# k and returns k centroids (which define clusters of data in the\n",
    "# dataset which are similar to one another).\n",
    "def kmeans(dataSet, k):\n",
    "\t\n",
    "    # Initialize centroids randomly\n",
    "    numFeatures = dataSet.getNumFeatures()\n",
    "    centroids = getRandomCentroids(numFeatures, k)\n",
    "    \n",
    "    # Initialize book keeping vars.\n",
    "    iterations = 0\n",
    "    oldCentroids = None\n",
    "    \n",
    "    # Run the main k-means algorithm\n",
    "    while not shouldStop(oldCentroids, centroids, iterations):\n",
    "        # Save old centroids for convergence test. Book keeping.\n",
    "        oldCentroids = centroids\n",
    "        iterations += 1\n",
    "        \n",
    "        # Assign labels to each datapoint based on centroids\n",
    "        labels = getLabels(dataSet, centroids)\n",
    "        \n",
    "        # Assign centroids based on datapoint labels\n",
    "        centroids = getCentroids(dataSet, labels, k)\n",
    "        \n",
    "    # We can get the labels too by calling getLabels(dataSet, centroids)\n",
    "    return centroids\n",
    "\n",
    "# Function: Should Stop\n",
    "# -------------\n",
    "# Returns True or False if k-means is done. K-means terminates either\n",
    "# because it has run a maximum number of iterations OR the centroids\n",
    "# stop changing.\n",
    "def shouldStop(oldCentroids, centroids, iterations):\n",
    "    if iterations > MAX_ITERATIONS: return True\n",
    "    return oldCentroids == centroids\n",
    "\n",
    "# Function: Get Labels\n",
    "# -------------\n",
    "# Returns a label for each piece of data in the dataset. \n",
    "def getLabels(dataSet, centroids):\n",
    "    # For each element in the dataset, chose the closest centroid. \n",
    "    # Make that centroid the element's label.\n",
    "\n",
    "# Function: Get Centroids\n",
    "# -------------\n",
    "# Returns k random centroids, each of dimension n.\n",
    "def getCentroids(dataSet, labels, k):\n",
    "    # Each centroid is the geometric mean of the points that\n",
    "    # have that centroid's label. Important: If a centroid is empty (no points have\n",
    "    # that centroid's label) you should randomly re-initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.6tf1.3keras]",
   "language": "python",
   "name": "conda-env-py3.6tf1.3keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
